{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8eeef64f",
   "metadata": {},
   "source": [
    "# IBM stance detection with topics and arguments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71fdf301",
   "metadata": {},
   "source": [
    "Stance detection of the IBM datasets using topics and arguments as input to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003c7b7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:58:35.787115Z",
     "start_time": "2023-03-27T16:58:31.240657Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "#shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d28b7f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:58:35.826822Z",
     "start_time": "2023-03-27T16:58:35.808764Z"
    }
   },
   "outputs": [],
   "source": [
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "652fb926",
   "metadata": {},
   "source": [
    "## 1. Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437a8ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:58:35.853541Z",
     "start_time": "2023-03-27T16:58:35.841878Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = '../data/ibm_train.csv'\n",
    "test_path = '../data/ibm_test.csv'\n",
    "\n",
    "plots_path = '../plots/topics and arguments/'\n",
    "models_path = '../models/topics and arguments/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9691330",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae18400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:58:35.902288Z",
     "start_time": "2023-03-27T16:58:35.882071Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29155d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:58:35.928987Z",
     "start_time": "2023-03-27T16:58:35.906516Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca1541ca",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b867c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:58:37.164469Z",
     "start_time": "2023-03-27T16:58:37.140474Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(test_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3d28d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:58:37.190482Z",
     "start_time": "2023-03-27T16:58:37.169275Z"
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a2d7767",
   "metadata": {},
   "source": [
    "Concatenate the topic and the argument for each example in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57556268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['argument'] = train['topic'] + ' ' + train['argument']\n",
    "#test['argument'] = test['topic'] + ' ' + test['argument']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b205d58",
   "metadata": {},
   "source": [
    "## 2. Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c99aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from autocorrect import Speller\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88de58c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:58:38.437276Z",
     "start_time": "2023-03-27T16:58:38.426214Z"
    }
   },
   "outputs": [],
   "source": [
    "# lower\n",
    "# remove extra whitespace\n",
    "# tokenize\n",
    "# spelling corrections\n",
    "# remove stopwords (da verificare se migliora o peggiora)\n",
    "# remove punctation\n",
    "# lemmatization\n",
    "# stemming \n",
    "# remove urls\n",
    "# remove tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6bcee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:58:38.551984Z",
     "start_time": "2023-03-27T16:58:38.528123Z"
    }
   },
   "outputs": [],
   "source": [
    "class PreprocessArguments:\n",
    "    def __init__(self):\n",
    "        self.spell = Speller(lang='en')\n",
    "        self.stopwords_set = set(stopwords.words('english'))\n",
    "        self.punct_remover = RegexpTokenizer(r'\\w+')\n",
    "        self.porter = PorterStemmer()\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    \n",
    "    def preprocess(self, s):    \n",
    "        # lowercase\n",
    "        s = s.lower()\n",
    "        # remove double whitespaces\n",
    "        s = ' '.join(s.split())\n",
    "        # tokenize\n",
    "        s = word_tokenize(s)\n",
    "        # spell correction\n",
    "        s = [self.spell(word) for word in s]\n",
    "        # remove punctuation\n",
    "        s = self.punct_remover.tokenize(' '.join(s))\n",
    "        # remove stopwords\n",
    "        s = [word for word in s if word not in self.stopwords_set]\n",
    "        # stemming\n",
    "        s = [self.porter.stem(word) for word in s]\n",
    "        #lemmatization\n",
    "        #s = [self.wnl.lemmatize(word) for word in s]\n",
    "        \n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1220d2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:58:38.725705Z",
     "start_time": "2023-03-27T16:58:38.560908Z"
    }
   },
   "outputs": [],
   "source": [
    "preproc = PreprocessArguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b27dac2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:59:12.259610Z",
     "start_time": "2023-03-27T16:58:38.731644Z"
    }
   },
   "outputs": [],
   "source": [
    "train['arg_tok'] = [preproc.preprocess(row['argument']) for idx, row in train.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aefb4fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:59:24.446672Z",
     "start_time": "2023-03-27T16:59:12.265768Z"
    }
   },
   "outputs": [],
   "source": [
    "test['arg_tok'] = [preproc.preprocess(row['argument']) for idx, row in test.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a4b0a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:59:24.478467Z",
     "start_time": "2023-03-27T16:59:24.449039Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "545a3e7c",
   "metadata": {},
   "source": [
    "## 3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5a5ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2acdd453",
   "metadata": {},
   "source": [
    "### 3.1 Baseline: Naive Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4b85acf",
   "metadata": {},
   "source": [
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2123d69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:59:55.914096Z",
     "start_time": "2023-03-27T16:59:55.909611Z"
    }
   },
   "outputs": [],
   "source": [
    "def dummy_tokenizer(sentence):\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c6276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:59:55.968325Z",
     "start_time": "2023-03-27T16:59:55.919452Z"
    }
   },
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(train['stance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab77f36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:59:55.986649Z",
     "start_time": "2023-03-27T16:59:55.978346Z"
    }
   },
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'f1_macro', 'precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f14e54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:59:56.005086Z",
     "start_time": "2023-03-27T16:59:55.996939Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preproc', TfidfVectorizer()), ('nb', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb59ea2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T09:34:37.075790Z",
     "start_time": "2023-03-27T09:34:37.070370Z"
    }
   },
   "outputs": [],
   "source": [
    "params = [\n",
    "    {'preproc': [TfidfVectorizer()],\n",
    "     'preproc__tokenizer': [dummy_tokenizer],\n",
    "     'preproc__preprocessor': [dummy_tokenizer],\n",
    "     'preproc__token_pattern': [None],\n",
    "     #'preproc__min_df': [1, 10, 20, 50, 100, 200],\n",
    "     'preproc__min_df': np.arange(1,6,1),\n",
    "     #'preproc__max_features': [None, 100, 200, 500],\n",
    "     #'preproc__ngram_range': [(1,1), (1,2), (1,3), (1,4)],\n",
    "     'preproc__ngram_range': [(1,1)],\n",
    "     \n",
    "     'nb': [MultinomialNB()],\n",
    "     #'nb__alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "     #'nb__alpha': [0.01, 0.05, 0.08, 0.1, 0.5, 0.8, 1, 5, 8]\n",
    "     'nb__alpha': np.arange(0.01,0.2,0.01)\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeb961f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T09:34:37.515961Z",
     "start_time": "2023-03-27T09:34:37.509425Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(estimator=pipe, param_grid=params, scoring=scoring, refit='f1_macro',\n",
    "                   cv=3, return_train_score=True, n_jobs=-1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d754970",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T09:35:43.279554Z",
     "start_time": "2023-03-27T09:34:37.970000Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.fit(train['arg_tok'], y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec840c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T09:35:43.330371Z",
     "start_time": "2023-03-27T09:35:43.293048Z"
    }
   },
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c797875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d94ff18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T09:35:43.377093Z",
     "start_time": "2023-03-27T09:35:43.339577Z"
    }
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(clf.cv_results_).sort_values(by='rank_test_f1_macro')[['mean_test_f1_macro', 'param_nb__alpha', 'param_preproc__ngram_range', 'param_preproc__min_df']][:40]\n",
    "#tmp = pd.DataFrame(clf.cv_results_).sort_values(by='rank_test_f1_macro')[['mean_test_f1_macro', 'param_nb', 'param_preproc__ngram_range', 'param_preproc__min_df']][:600]\n",
    "#tmp.groupby(by='param_preproc__min_df').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94c7dbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T09:35:45.471620Z",
     "start_time": "2023-03-27T09:35:43.383430Z"
    }
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(clf.cv_results_).to_csv(models_path+'nb_gridsearch.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0bce6a66",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ac781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T09:36:34.169815Z",
     "start_time": "2023-03-27T09:36:34.100434Z"
    }
   },
   "outputs": [],
   "source": [
    "best_clf = clf.best_estimator_\n",
    "best_clf.fit(train['arg_tok'], y_train.ravel())\n",
    "pred_test = best_clf.predict(test['arg_tok'])\n",
    "y_test = lb.transform(test['stance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d552373",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T09:39:45.140731Z",
     "start_time": "2023-03-27T09:39:44.743902Z"
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, pred_test)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lb.inverse_transform(clf.classes_)).plot(ax=ax)\n",
    "plt.savefig(plots_path+'nb_cm.png', bbox_inches =\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c96ae91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T09:40:13.463278Z",
     "start_time": "2023-03-27T09:40:13.440384Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dcdbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = test.copy()\n",
    "tmp['pred'] = lb.inverse_transform(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2194aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['TP'] = tmp.apply(lambda row: row['stance'] == row['pred'] and row['stance'] == 'PRO', axis=1)\n",
    "tmp['TN'] = tmp.apply(lambda row: row['stance'] == row['pred'] and row['stance'] == 'CON', axis=1)\n",
    "tmp['FP'] = tmp.apply(lambda row: row['stance'] != row['pred'] and row['stance'] == 'CON', axis=1)\n",
    "tmp['FN'] = tmp.apply(lambda row: row['stance'] != row['pred'] and row['stance'] == 'PRO', axis=1)\n",
    "tmp['T'] = tmp.apply(lambda row: row['stance'] == row['pred'], axis=1)\n",
    "tmp['F'] = tmp.apply(lambda row: row['stance'] != row['pred'], axis=1)\n",
    "tmp = tmp.groupby(by='topic').agg({'TP': 'sum',\n",
    "                                   'TN': 'sum',\n",
    "                                   'FP': 'sum',\n",
    "                                   'FN': 'sum',\n",
    "                                   'T': 'sum',\n",
    "                                   'F': 'sum'}).reset_index()\n",
    "tmp.sort_values(by='topic', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb87453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(tmp['topic'], tmp['T']/(tmp['T']+tmp['F'])*100, label='Correctly predicted')\n",
    "plt.bar(tmp['topic'], tmp['F']/(tmp['T']+tmp['F'])*100, bottom=tmp['T']/(tmp['T']+tmp['F'])*100, label='Incorrectly predicted')\n",
    "plt.title('Percentage of correctly and incorrectly predicted arguments by categories')\n",
    "plt.ylabel('Percentage of arguments')\n",
    "plt.yticks(np.arange(0,110,10))\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.legend()\n",
    "plt.savefig(plots_path+'nb_prediction_percentage.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe54a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(tmp['topic'], tmp['TP'], label='TP')\n",
    "plt.bar(tmp['topic'], tmp['TN'], bottom=tmp['TP'], label='TN')\n",
    "plt.bar(tmp['topic'], tmp['FP'], bottom=tmp['TP']+tmp['TN'], label='FP')\n",
    "plt.bar(tmp['topic'], tmp['FN'], bottom=tmp['TP']+tmp['TN']+tmp['FP'], label='FN')\n",
    "plt.title('Confusion matrix by categories')\n",
    "plt.ylabel('# of arguments')\n",
    "plt.yticks(np.arange(0,65,5))\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.legend()\n",
    "plt.savefig(plots_path+'nb_cm_categories.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bc8de99",
   "metadata": {},
   "source": [
    "#### Shap analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(best_clf.named_steps['nb'].predict,\n",
    "                           best_clf.named_steps['preproc'].transform(train['arg_tok']).toarray(),\n",
    "                           feature_names=best_clf.named_steps['preproc'].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf66667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(best_clf.named_steps['preproc'].transform(test['arg_tok'][:20]).toarray(), max_evals='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6198ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values, max_display=10, order=shap_values.abs.max(0), show=False)\n",
    "plt.savefig(plots_path+'nb_shap_beeswarm.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b3de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['stance'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca52dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap.force_plot(shap_values[0])\n",
    "shap.force_plot(shap_values[5], link='logit', matplotlib=True, show=False) \n",
    "plt.savefig(plots_path+'nb_shap_force_PRO.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a910d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_values[18], link='logit', matplotlib=True, show=False) \n",
    "plt.savefig(plots_path+'nb_shap_force_CON.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2872f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.heatmap(shap_values, instance_order=shap_values.sum(1), max_display=10, show=False)\n",
    "plt.savefig(plots_path+'nb_shap_heatmap.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7821520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[5], max_display=10, show=False)\n",
    "plt.savefig(plots_path+'nb_shap_waterfall_PRO.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02db6a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[18], max_display=10, show=False)\n",
    "plt.savefig(plots_path+'nb_shap_waterfall_CON.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14f016f4",
   "metadata": {},
   "source": [
    "### 3.2 SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "854c7529",
   "metadata": {},
   "source": [
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d92dbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:59:56.029734Z",
     "start_time": "2023-03-27T16:59:56.021283Z"
    }
   },
   "outputs": [],
   "source": [
    "def dummy_tokenizer(sentence):\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b986e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(train['stance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887b32d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:59:56.046014Z",
     "start_time": "2023-03-27T16:59:56.035768Z"
    }
   },
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'f1_macro', 'precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228bfa57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T16:59:56.064201Z",
     "start_time": "2023-03-27T16:59:56.054355Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preproc', TfidfVectorizer()), ('svm', SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3526b6f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:28:06.095572Z",
     "start_time": "2023-03-27T19:28:06.086468Z"
    }
   },
   "outputs": [],
   "source": [
    "params = [\n",
    "    {'preproc': [TfidfVectorizer()],\n",
    "     'preproc__tokenizer': [dummy_tokenizer],\n",
    "     'preproc__preprocessor': [dummy_tokenizer],\n",
    "     'preproc__token_pattern': [None],\n",
    "     #'preproc__min_df': [1, 10, 20, 50, 100],\n",
    "     #'preproc__min_df': np.arange(1,6,1),\n",
    "     'preproc__min_df': [1],\n",
    "     #'preproc__max_features': [None, 100, 200, 300, 400, 500, 600],\n",
    "     #'preproc__ngram_range': [(1,1), (1,2), (1,3), (2,3), (1,4)],\n",
    "     #'preproc__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "     'preproc__ngram_range': [(1,1)],\n",
    "     \n",
    "     'svm': [SVC()],\n",
    "     #'svm__C': [0.1, 1, 2, 5, 10, 50],\n",
    "     'svm__C': np.arange(1,3,0.01),\n",
    "     #'svm__C': np.arange(1,6,1),\n",
    "     'svm__kernel': ['poly'],\n",
    "     #'svm__degree': [2, 3, 4, 5],\n",
    "     #'svm__degree': np.arange(2,5,1),\n",
    "     'svm__degree': [2],\n",
    "     'svm__gamma': ['scale'],\n",
    "     #'svm__shrinking': [True, False],     \n",
    "    },\n",
    "    \n",
    "    #{'preproc': [TfidfVectorizer()],\n",
    "     #'preproc__tokenizer': [dummy_tokenizer],\n",
    "     #'preproc__preprocessor': [dummy_tokenizer],\n",
    "     #'preproc__token_pattern': [None],\n",
    "     #'preproc__min_df': [1, 10, 20, 50, 100],\n",
    "     #'preproc__min_df': np.arange(1,6,1),\n",
    "     #'preproc__max_features': [None, 100, 200, 300, 400, 500, 600],\n",
    "     #'preproc__ngram_range': [(1,1), (1,2), (1,3), (2,3), (1,4)],\n",
    "     #'preproc__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "     #'preproc__ngram_range': [(1,1)],\n",
    "     \n",
    "     #'svm': [SVC()],\n",
    "     #'svm__C': [0.1, 1, 2, 5, 10, 50],\n",
    "     #'svm__C': np.arange(1,15,0.5),\n",
    "     #'svm__kernel': ['rbf', 'sigmoid'],\n",
    "     #'svm__gamma': ['scale'],\n",
    "     #'svm__kernel': ['rbf'],\n",
    "     #'svm__shrinking': [True, False],     \n",
    "    #},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865cb9d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:28:08.681753Z",
     "start_time": "2023-03-27T19:28:08.674815Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(estimator=pipe, param_grid=params, scoring=scoring, refit='f1_macro',\n",
    "                   cv=3, return_train_score=True, n_jobs=-1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05db5fb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:33:32.432991Z",
     "start_time": "2023-03-27T19:28:09.855228Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.fit(train['arg_tok'], y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2cf40b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:33:32.447954Z",
     "start_time": "2023-03-27T19:33:32.438910Z"
    }
   },
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53528ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0b5517",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:33:32.459879Z",
     "start_time": "2023-03-27T19:33:32.453223Z"
    }
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(clf.cv_results_).sort_values(by='rank_test_f1_macro')[['mean_test_f1_macro', 'param_svm__kernel', 'param_svm__C', 'param_svm__degree', 'param_preproc__ngram_range', 'param_preproc__min_df']][:60]\n",
    "#tmp = pd.DataFrame(clf.cv_results_).sort_values(by='rank_test_f1_macro')[['mean_test_f1_macro', 'param_svm__C', 'param_svm__degree', 'param_preproc__min_df', 'param_preproc__ngram_range']][:120]\n",
    "#tmp.groupby(by=['param_preproc__min_df', 'param_preproc__ngram_range']).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755fb9c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:33:32.505850Z",
     "start_time": "2023-03-27T19:33:32.497458Z"
    }
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(clf.cv_results_).to_csv(models_path+'svc_gridsearch3.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28da77e2",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e37839",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:33:32.823000Z",
     "start_time": "2023-03-27T19:33:32.511482Z"
    }
   },
   "outputs": [],
   "source": [
    "best_clf = clf.best_estimator_\n",
    "best_clf.fit(train['arg_tok'], y_train.ravel())\n",
    "pred_test = best_clf.predict(test['arg_tok'])\n",
    "y_test = lb.transform(test['stance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb00748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:33:33.285979Z",
     "start_time": "2023-03-27T19:33:32.826537Z"
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, pred_test)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lb.inverse_transform(clf.classes_)).plot(ax=ax)\n",
    "plt.savefig(plots_path+'svc_cm.png', bbox_inches =\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f5fc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T19:33:33.313777Z",
     "start_time": "2023-03-27T19:33:33.290542Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b0cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = test.copy()\n",
    "tmp['pred'] = lb.inverse_transform(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47fdf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['TP'] = tmp.apply(lambda row: row['stance'] == row['pred'] and row['stance'] == 'PRO', axis=1)\n",
    "tmp['TN'] = tmp.apply(lambda row: row['stance'] == row['pred'] and row['stance'] == 'CON', axis=1)\n",
    "tmp['FP'] = tmp.apply(lambda row: row['stance'] != row['pred'] and row['stance'] == 'CON', axis=1)\n",
    "tmp['FN'] = tmp.apply(lambda row: row['stance'] != row['pred'] and row['stance'] == 'PRO', axis=1)\n",
    "tmp['T'] = tmp.apply(lambda row: row['stance'] == row['pred'], axis=1)\n",
    "tmp['F'] = tmp.apply(lambda row: row['stance'] != row['pred'], axis=1)\n",
    "tmp = tmp.groupby(by='topic').agg({'TP': 'sum',\n",
    "                                   'TN': 'sum',\n",
    "                                   'FP': 'sum',\n",
    "                                   'FN': 'sum',\n",
    "                                   'T': 'sum',\n",
    "                                   'F': 'sum'}).reset_index()\n",
    "tmp.sort_values(by='topic', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3058d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(tmp['topic'], tmp['T']/(tmp['T']+tmp['F'])*100, label='Correctly predicted')\n",
    "plt.bar(tmp['topic'], tmp['F']/(tmp['T']+tmp['F'])*100, bottom=tmp['T']/(tmp['T']+tmp['F'])*100, label='Incorrectly predicted')\n",
    "plt.title('Percentage of correctly and incorrectly predicted arguments by categories')\n",
    "plt.ylabel('Percentage of arguments')\n",
    "plt.yticks(np.arange(0,110,10))\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.legend()\n",
    "plt.savefig(plots_path+'svc_prediction_percentage.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762e8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(tmp['topic'], tmp['TP'], label='TP')\n",
    "plt.bar(tmp['topic'], tmp['TN'], bottom=tmp['TP'], label='TN')\n",
    "plt.bar(tmp['topic'], tmp['FP'], bottom=tmp['TP']+tmp['TN'], label='FP')\n",
    "plt.bar(tmp['topic'], tmp['FN'], bottom=tmp['TP']+tmp['TN']+tmp['FP'], label='FN')\n",
    "plt.title('Confusion matrix by categories')\n",
    "plt.ylabel('# of arguments')\n",
    "plt.yticks(np.arange(0,65,5))\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.legend()\n",
    "plt.savefig(plots_path+'svc_cm_categories.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d6cc02c",
   "metadata": {},
   "source": [
    "#### Shap analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81537ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(best_clf.named_steps['svm'].predict,\n",
    "                           best_clf.named_steps['preproc'].transform(train['arg_tok']).toarray(),\n",
    "                           feature_names=best_clf.named_steps['preproc'].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a4ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(best_clf.named_steps['preproc'].transform(test['arg_tok'][:20]).toarray(),\n",
    "                        max_evals='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d83613",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values, max_display=10, order=shap_values.abs.max(0), show=False)\n",
    "plt.savefig(plots_path+'svc_shap_beeswarm.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30638acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['stance'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba12dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap.force_plot(shap_values[0])\n",
    "shap.force_plot(shap_values[5], link='logit', matplotlib=True, show=False) \n",
    "plt.savefig(plots_path+'svc_shap_force_PRO.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0cb4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_values[2], link='logit', matplotlib=True, show=False) \n",
    "plt.savefig(plots_path+'svc_shap_force_CON.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2293953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.heatmap(shap_values, instance_order=shap_values.sum(1), max_display=10, show=False)\n",
    "plt.savefig(plots_path+'svc_shap_heatmap.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812c6dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[5], max_display=10, show=False)\n",
    "plt.savefig(plots_path+'svc_shap_waterfall_PRO.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e57c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[2], max_display=10, show=False)\n",
    "plt.savefig(plots_path+'svc_shap_waterfall_CON.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8c3ac8f",
   "metadata": {},
   "source": [
    "### 3.3 BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac203e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, pipeline, AutoModel, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, f1_score\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b010318",
   "metadata": {},
   "source": [
    "#### Load and encode the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bert, val_bert = train_test_split(train, test_size=0.2, random_state=42, stratify=train[['stance', 'topic']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c2bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bert = Dataset.from_pandas(train_bert[['argument', 'topic', 'stance']], split='train', preserve_index=False)\n",
    "val_bert = Dataset.from_pandas(val_bert[['argument', 'topic', 'stance']], split='validation', preserve_index=False)\n",
    "test_bert = Dataset.from_pandas(test[['argument', 'topic', 'stance']], split='test', preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_dataset = DatasetDict(train=train_bert, val=val_bert, test=test_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de8cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"CON\", 1: \"PRO\"}\n",
    "label2id = {\"CON\": 0, \"PRO\": 1}\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6e18ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    encoding = tokenizer(data['argument'],\n",
    "                        add_special_tokens=True,\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        max_length=64)\n",
    "    encoding['labels'] = [label2id[l] for l in data['stance']]\n",
    "    tok_topic = tokenizer(data['topic'],\n",
    "                          add_special_tokens=True,\n",
    "                          padding='max_length',\n",
    "                          truncation=True,\n",
    "                          max_length=64)\n",
    "    encoding['topic_input_ids'] = tok_topic['input_ids']\n",
    "    encoding['topic_attention_mask'] = tok_topic['attention_mask']\n",
    "    encoding['topic_token_type_ids'] = tok_topic['token_type_ids']\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d56c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = ibm_dataset.map(preprocess_data, batched=True, batch_size=16, remove_columns=['argument', 'topic', 'stance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff579a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset.set_format('torch')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43dde018",
   "metadata": {},
   "source": [
    "#### Finetune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c21e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTStance(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size*2, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        # Freeze BERT parameters\n",
    "        #for param in self.bert.parameters():\n",
    "        #    param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, topic_input_ids, topic_attention_mask, topic_token_type_ids):\n",
    "        out_arg = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids)\n",
    "        #out_arg = self.dropout(out_arg['pooler_output'])\n",
    "        out_arg = out_arg['last_hidden_state'][:,0,:]\n",
    "        #out_arg = out_arg['pooler_output']\n",
    "\n",
    "        out_topic = self.bert(input_ids=topic_input_ids,\n",
    "                              attention_mask=topic_attention_mask,\n",
    "                              token_type_ids=topic_token_type_ids)\n",
    "\n",
    "        #out_topic = self.dropout(out_topic['pooler_output'])\n",
    "        out_topic = out_topic['last_hidden_state'][:,0,:]\n",
    "        #out_topic = out_topic['pooler_output']\n",
    "        \n",
    "        out = torch.cat((out_arg, out_topic), dim=1)\n",
    "        out = self.dropout(out)\n",
    "        logits = self.classifier(out)\n",
    "        probs = self.softmax(logits)\n",
    "        return logits, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3c9826",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTStance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainloop(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    best_model = None\n",
    "    loss_epochs = {'train': [], 'val': []}\n",
    "    f1_epochs = {'train': [], 'val': []}\n",
    "\n",
    "    # Set parameters\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_data)*epochs)\n",
    "\n",
    "    device = torch.device('cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        # Training loop\n",
    "        loss = 0\n",
    "        f1 = 0\n",
    "        model.train()\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_data):\n",
    "            \n",
    "            # zero out previous gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            logits, probs = model(batch['input_ids'].to(device),\n",
    "                                attention_mask=batch['attention_mask'].to(device),\n",
    "                                token_type_ids=batch['token_type_ids'].to(device),\n",
    "                                topic_input_ids=batch['topic_input_ids'].to(device),\n",
    "                                topic_attention_mask=batch['topic_attention_mask'].to(device),\n",
    "                                topic_token_type_ids=batch['topic_token_type_ids'].to(device))\n",
    "\n",
    "\n",
    "            # Compute loss and backpropagte\n",
    "            batch_loss = loss_fn(logits, batch['labels'].to(device))\n",
    "            loss += batch_loss.item()\n",
    "            batch_loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # update parameters and learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # compute f1 score\n",
    "            pred = torch.argmax(probs, dim=1).cpu().numpy()\n",
    "            f1 += f1_score(batch['labels'].cpu().numpy(), pred, average='macro')\n",
    "\n",
    "        print(f\"Train epoch {epoch} - Loss: {loss / len(train_data)} - F1: {f1 / len(train_data)}\")\n",
    "\n",
    "        loss_epochs['train'].append(loss / len(train_data))\n",
    "        f1_epochs['train'].append(f1 / len(train_data))\n",
    "\n",
    "        # Validation loop\n",
    "        loss = 0\n",
    "        f1 = 0\n",
    "        model.eval()\n",
    "\n",
    "        for batch_idx, batch in enumerate(val_data):\n",
    "            with torch.no_grad():\n",
    "                logits, probs = model(batch['input_ids'].to(device),\n",
    "                                    attention_mask=batch['attention_mask'].to(device),\n",
    "                                    token_type_ids=batch['token_type_ids'].to(device),\n",
    "                                    topic_input_ids=batch['topic_input_ids'].to(device),\n",
    "                                    topic_attention_mask=batch['topic_attention_mask'].to(device),\n",
    "                                    topic_token_type_ids=batch['topic_token_type_ids'].to(device))\n",
    "\n",
    "            # Compute loss\n",
    "            loss += loss_fn(logits, batch['labels'].to(device)).item()\n",
    "\n",
    "            # compute f1 score\n",
    "            pred = torch.argmax(probs, dim=1).cpu().numpy()\n",
    "            f1 += f1_score(batch['labels'].cpu().numpy(), pred, average='macro')\n",
    "\n",
    "        print(f\"Val epoch {epoch} - Loss: {loss / len(val_data)} - F1: {f1 / len(val_data)}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if f1 / len(val_data) >= best_f1:\n",
    "            best_f1 = f1 / len(val_data)\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), models_path+'bert_stance_t.pt')\n",
    "\n",
    "        loss_epochs['val'].append(loss / len(val_data))\n",
    "        f1_epochs['val'].append(f1 / len(val_data))\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model)\n",
    "    return model, loss_epochs, f1_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 5\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_dataset['train'], batch_size=batch_size)\n",
    "eval_dataloader = DataLoader(tokenized_dataset['val'], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47332261",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_epochs, f1_epochs = trainloop(model, train_dataloader, eval_dataloader, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa93d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7cff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761d837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(models_path+'bert_f1_t.json', 'w') as fp:\n",
    "    json.dump(f1_epochs, fp)\n",
    "\n",
    "with open(models_path+'bert_loss_t.json', 'w') as fp:\n",
    "    json.dump(loss_epochs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc48b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dataloader = DataLoader(tokenized_dataset['test'], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3c0bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cpu')\n",
    "#model.to(device)\n",
    "\n",
    "#all_pred = []\n",
    "#model.eval()\n",
    "\n",
    "#for batch_idx, batch in enumerate(test_dataloader):\n",
    "#    with torch.no_grad():\n",
    "#        logits, probs = model(batch['input_ids'].to(device),\n",
    "#                            attention_mask=batch['attention_mask'].to(device),\n",
    "#                            token_type_ids=batch['token_type_ids'].to(device),\n",
    "#                            topic_input_ids=batch['topic_input_ids'].to(device),\n",
    "#                            topic_attention_mask=batch['topic_attention_mask'].to(device),\n",
    "#                            topic_token_type_ids=batch['topic_token_type_ids'].to(device))\n",
    "\n",
    "#    pred = torch.argmax(probs, dim=1).cpu().numpy()\n",
    "#    all_pred.extend(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729c7c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test = tokenized_dataset['test']['labels'].numpy()\n",
    "#y_pred = np.array(all_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d7b1844",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd17cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model = BERTStance()\n",
    "finetuned_model.load_state_dict(torch.load(models_path+'bert_stance_t.pt'))\n",
    "id2label = {0: \"CON\", 1: \"PRO\"}\n",
    "label2id = {\"CON\": 0, \"PRO\": 1}\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fafdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer(test['argument'].to_list(),\n",
    "                        add_special_tokens=True,\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        max_length=64,\n",
    "                        return_tensors='pt')\n",
    "tok_topic = tokenizer(test['topic'],\n",
    "                        add_special_tokens=True,\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de123b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits, probs = finetuned_model(model_inputs['input_ids'],\n",
    "                                    attention_mask=model_inputs['attention_mask'],\n",
    "                                    token_type_ids=model_inputs['token_type_ids'],\n",
    "                                    topic_input_ids=tok_topic['input_ids'],\n",
    "                                    topic_attention_mask=tok_topic['attention_mask'],\n",
    "                                    topic_token_type_ids=tok_topic['token_type_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e8a9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.argmax(probs, dim=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f2bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [label2id[l] for l in test['stance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0884bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['CON', 'PRO']).plot(ax=ax)\n",
    "plt.savefig(plots_path+'bert_cm_t.png', bbox_inches =\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242848d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38590af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = test.copy()\n",
    "tmp['pred'] = [id2label[i] for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1107e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['TP'] = tmp.apply(lambda row: row['stance'] == row['pred'] and row['stance'] == 'PRO', axis=1)\n",
    "tmp['TN'] = tmp.apply(lambda row: row['stance'] == row['pred'] and row['stance'] == 'CON', axis=1)\n",
    "tmp['FP'] = tmp.apply(lambda row: row['stance'] != row['pred'] and row['stance'] == 'CON', axis=1)\n",
    "tmp['FN'] = tmp.apply(lambda row: row['stance'] != row['pred'] and row['stance'] == 'PRO', axis=1)\n",
    "tmp['T'] = tmp.apply(lambda row: row['stance'] == row['pred'], axis=1)\n",
    "tmp['F'] = tmp.apply(lambda row: row['stance'] != row['pred'], axis=1)\n",
    "tmp = tmp.groupby(by='topic').agg({'TP': 'sum',\n",
    "                                   'TN': 'sum',\n",
    "                                   'FP': 'sum',\n",
    "                                   'FN': 'sum',\n",
    "                                   'T': 'sum',\n",
    "                                   'F': 'sum'}).reset_index()\n",
    "tmp.sort_values(by='topic', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8aa910",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(tmp['topic'], tmp['T']/(tmp['T']+tmp['F'])*100, label='Correctly predicted')\n",
    "plt.bar(tmp['topic'], tmp['F']/(tmp['T']+tmp['F'])*100, bottom=tmp['T']/(tmp['T']+tmp['F'])*100, label='Incorrectly predicted')\n",
    "plt.title('Percentage of correctly and incorrectly predicted arguments by categories')\n",
    "plt.ylabel('Percentage of arguments')\n",
    "plt.yticks(np.arange(0,110,10))\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.legend()\n",
    "plt.savefig(plots_path+'bert_prediction_percentage_t.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7405e636",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(tmp['topic'], tmp['TP'], label='TP')\n",
    "plt.bar(tmp['topic'], tmp['TN'], bottom=tmp['TP'], label='TN')\n",
    "plt.bar(tmp['topic'], tmp['FP'], bottom=tmp['TP']+tmp['TN'], label='FP')\n",
    "plt.bar(tmp['topic'], tmp['FN'], bottom=tmp['TP']+tmp['TN']+tmp['FP'], label='FN')\n",
    "plt.title('Confusion matrix by categories')\n",
    "plt.ylabel('# of arguments')\n",
    "plt.yticks(np.arange(0,65,5))\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.legend()\n",
    "plt.savefig(plots_path+'bert_cm_categories_t.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2146df5",
   "metadata": {},
   "source": [
    "#### Shap analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee16adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pipeline(\"text-classification\", model=finetuned_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a721f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffe38cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(test['argument'][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a312211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values[:,:,1].mean(0), max_display=10, show=False)\n",
    "plt.savefig(plots_path+'bert_shap_PRO.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f730dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values[:,:,0].mean(0), max_display=10, show=False)\n",
    "plt.savefig(plots_path+'bert_shap_CON.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502eb115",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['stance'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b158ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[0,:,1], max_display=10, show=False)\n",
    "plt.savefig(plots_path+'bert_shap_waterfall_PRO.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[11,:,0], max_display=10, show=False)\n",
    "plt.savefig(plots_path+'bert_shap_waterfall_CON.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dfff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values[0,:,1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64c734f2",
   "metadata": {},
   "source": [
    "### 3.4 Prompt tuning GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f40fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback, pipeline\n",
    "from peft import PromptTuningConfig, PromptTuningInit, PeftType, TaskType, get_peft_model, PromptEncoderConfig, PeftConfig, PeftModel\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluate\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0da61998",
   "metadata": {},
   "source": [
    "#### Load and encode the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb68df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bert, val_bert = train_test_split(train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f8c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bert = Dataset.from_pandas(train_bert[['argument', 'stance']], split='train', preserve_index=False)\n",
    "val_bert = Dataset.from_pandas(val_bert[['argument', 'stance']], split='validation', preserve_index=False)\n",
    "test_bert = Dataset.from_pandas(test[['argument', 'stance']], split='test', preserve_index=False)\n",
    "ibm_dataset = DatasetDict(train=train_bert, val=val_bert, test=test_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaa20c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"CON\", 1: \"PRO\"}\n",
    "label2id = {\"CON\": 0, \"PRO\": 1}\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", truncation=True, padding_side='left')\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b5a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    encoding = tokenizer(data['argument'], padding=True)\n",
    "    encoding['labels'] = [label2id[l] for l in data['stance']]\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = ibm_dataset.map(preprocess_data, batched=True, batch_size=16, remove_columns=['argument', 'stance'])\n",
    "tokenized_dataset.set_format('torch')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b44a135",
   "metadata": {},
   "source": [
    "#### Prompt tuning of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67cb646",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = PromptEncoderConfig(#PromptTuningConfig(\n",
    "    #peft_type=PeftType.PROMPT_TUNING,\n",
    "    peft_type=PeftType.P_TUNING,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    #prompt_tuning_init=PromptTuningInit.TEXT,\n",
    "    num_virtual_tokens=16,\n",
    "    #prompt_tuning_init_text='Detect if the stance of this tweet is PRO or CON:',\n",
    "    #tokenizer_name_or_path='gpt2',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e81f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"gpt2\",\n",
    "                                                           num_labels=2,\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb60582",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d2c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = TrainingArguments(\n",
    "    output_dir=models_path+'gpt2',\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    metric_for_best_model='f1',\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8453d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    return metrics.compute(predictions=predictions, references=labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c10b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=arguments,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "#trainer.add_callback(EarlyStoppingCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c89070",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce689da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(models_path+'gpt2/final_model')\n",
    "trainer.model.config.to_json_file(models_path+'gpt2/final_model/config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15b2c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.state.save_to_json(models_path+'gpt2/training_state.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1349c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(models_path+'gpt2/train_metrics.json', 'w') as fp:\n",
    "    json.dump(trainer.evaluate(tokenized_dataset['train']), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(models_path+'gpt2/val_metrics.json', 'w') as fp:\n",
    "    json.dump(trainer.evaluate(tokenized_dataset['val']), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f222303",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(models_path+'gpt2/test_metrics.json', 'w') as fp:\n",
    "    json.dump(trainer.evaluate(tokenized_dataset['test']), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f3b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_pred = trainer.predict(tokenized_dataset['test'])\n",
    "#y_pred = test_pred.predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec72c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test = tokenized_dataset['test']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9d8dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(y_test, test_pred.predictions.argmax(axis=1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cb49d10",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488e28e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = PeftConfig.from_pretrained(models_path+'gpt2/final_model')\n",
    "#inference_model = AutoModelForSequenceClassification.from_pretrained(config.base_model_name_or_path)\n",
    "ptuned_model = AutoModelForSequenceClassification.from_pretrained(models_path+'gpt2/final_model')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(models_path+'gpt2/final_model', padding_side='left')\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "#ptuned_model = PeftModel.from_pretrained(inference_model, models_path+'gpt2/final_model')\n",
    "ptuned_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb71f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"CON\", 1: \"PRO\"}\n",
    "label2id = {\"CON\": 0, \"PRO\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe2848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer(test['argument'].to_list(), return_tensors='pt', padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e683b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred = ptuned_model(**model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb7e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.argmax(pred.logits, axis=1).numpy()\n",
    "y_test = [label2id[l] for l in test['stance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8085ae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['CON', 'PRO']).plot(ax=ax)\n",
    "plt.savefig(plots_path+'gpt2_cm.png', bbox_inches =\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae4fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebef0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = test.copy()\n",
    "tmp['pred'] = [id2label[i] for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711cd142",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['TP'] = tmp.apply(lambda row: row['stance'] == row['pred'] and row['stance'] == 'PRO', axis=1)\n",
    "tmp['TN'] = tmp.apply(lambda row: row['stance'] == row['pred'] and row['stance'] == 'CON', axis=1)\n",
    "tmp['FP'] = tmp.apply(lambda row: row['stance'] != row['pred'] and row['stance'] == 'CON', axis=1)\n",
    "tmp['FN'] = tmp.apply(lambda row: row['stance'] != row['pred'] and row['stance'] == 'PRO', axis=1)\n",
    "tmp['T'] = tmp.apply(lambda row: row['stance'] == row['pred'], axis=1)\n",
    "tmp['F'] = tmp.apply(lambda row: row['stance'] != row['pred'], axis=1)\n",
    "tmp = tmp.groupby(by='topic').agg({'TP': 'sum',\n",
    "                                   'TN': 'sum',\n",
    "                                   'FP': 'sum',\n",
    "                                   'FN': 'sum',\n",
    "                                   'T': 'sum',\n",
    "                                   'F': 'sum'}).reset_index()\n",
    "tmp.sort_values(by='topic', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a526089",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(tmp['topic'], tmp['T']/(tmp['T']+tmp['F'])*100, label='Correctly predicted')\n",
    "plt.bar(tmp['topic'], tmp['F']/(tmp['T']+tmp['F'])*100, bottom=tmp['T']/(tmp['T']+tmp['F'])*100, label='Incorrectly predicted')\n",
    "plt.title('Percentage of correctly and incorrectly predicted arguments by categories')\n",
    "plt.ylabel('Percentage of arguments')\n",
    "plt.yticks(np.arange(0,110,10))\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.legend()\n",
    "plt.savefig(plots_path+'gpt2_prediction_percentage.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43186a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(tmp['topic'], tmp['TP'], label='TP')\n",
    "plt.bar(tmp['topic'], tmp['TN'], bottom=tmp['TP'], label='TN')\n",
    "plt.bar(tmp['topic'], tmp['FP'], bottom=tmp['TP']+tmp['TN'], label='FP')\n",
    "plt.bar(tmp['topic'], tmp['FN'], bottom=tmp['TP']+tmp['TN']+tmp['FP'], label='FN')\n",
    "plt.title('Confusion matrix by categories')\n",
    "plt.ylabel('# of arguments')\n",
    "plt.yticks(np.arange(0,65,5))\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.legend()\n",
    "plt.savefig(plots_path+'gpt2_cm_categories.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87c9ba9a",
   "metadata": {},
   "source": [
    "#### Shap analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4fc375",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pipeline(\"text-classification\", model=ptuned_model, tokenizer=tokenizer)\n",
    "explainer = shap.Explainer(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3ad4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(test['argument'][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023b3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values[:,:,1].mean(0), max_display=10, show=False)\n",
    "plt.savefig(plots_path+'gpt2_shap_PRO.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed1546",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values[:,:,0].mean(0), max_display=10, show=False)\n",
    "plt.savefig(plots_path+'gpt2_shap_CON.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac760f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['stance'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f0b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[5,:,1], max_display=10, show=False)\n",
    "plt.savefig(plots_path+'gpt2_shap_waterfall_PRO.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e328c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[2,:,0], max_display=10, show=False)\n",
    "plt.savefig(plots_path+'gpt2_shap_waterfall_CON.png', bbox_inches ='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values[2,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb13abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "216ddcf3",
   "metadata": {},
   "source": [
    "### 3.5 ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9da6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['stance'][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad6930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted stance only with arguments\n",
    "pred_stances = [\n",
    "    'PRO',  # knowledge should be \"shared in solidarity\"\n",
    "    'CON',  # faith  belief that is not based on evidence  is one of the world's great evils\n",
    "    'CON',  # dam construction requires the state to displace individual people\n",
    "    'CON',  # China's gender imbalance is further increased by the One Child Policy\n",
    "    'CON',  # laissez-faire capitalism creates social evils that harm its citizens\n",
    "    'CON',  # it was Hamas that broke the truce\n",
    "    'PRO',  # gambling increases aggregate demand for goods and services in the economy\n",
    "    'CON',  # A large dam can cause the loss of entire ecospheres\n",
    "    'CON',  # Damming can harm local ecosystems\n",
    "    'PRO',  # the focus of China on population control helps provide a better health service for women\n",
    "    'CON',  # A large dam can endanger ecosystems by restricting the motion of marine animals\n",
    "    'CON',  # the right to self-defence requires that peaceful means are first exhausted before resorting to military force, something Israel \"did not even contemplate doing\n",
    "    'PRO',  # Monarchy provides continuity and stability\n",
    "    'PRO',  # free trade gives optimal economic advantages\n",
    "    'CON',  # Advertising's cumulative cultural effects, unless quickly checked, will be responsible for destroying the world as we know it\n",
    "    'CON',  # video games allow children to act out crimes\n",
    "    'CON',  # advertising attempts to equate the social with the material by utilizing images and slogans to link commodities with the real sources of human happiness\n",
    "    'CON',  # a perfect God can have no need to create a world\n",
    "    'PRO',  # Intellectual property is viewed as a necessary way of incentivising the creation of new creative works\n",
    "    'CON',  # denying the existence of a god leads to moral relativism, leaving one with no moral or ethical foundation\n",
    "    'CON',  # welfare not only increases poverty but also increases other problems\n",
    "    'CON',  # The right to free speech conflicts with other rights\n",
    "    'CON',  # abstinence-only programs deprive teenagers of critical information about sexuality\n",
    "    'PRO',  # freedom of speech, in order to exist and function, necessarily extends to even the unpopular\n",
    "    'CON',  # Unfettered markets undermine the social order\n",
    "    'CON',  # Denying the existence of a god renders life meaningless and miserable\n",
    "    'CON',  # the universe can be explained without any reference to the supernatural\n",
    "    'CON',  # It is immoral to create children\n",
    "    'PRO',  # In charity gambling profits from the venture go to the charity or group of charities, rather than to a municipality or private casino\n",
    "    'CON',  # Faith is divisive and dangerous\n",
    "    'CON',  # studies of abstinence programs have not produced sufficient evidence to justify their widespread dissemination\n",
    "    'CON',  # Subsidies may distort production incentives\n",
    "    'CON',  # The blockade action is a violation of international law\n",
    "    'PRO',  # the average standard of living in a declining population, at least in terms of material possessions, will tend to rise\n",
    "    'CON',  # advertising focuses on looking toward external rewards for a sense of self\n",
    "    'CON',  # Providing safe-sex education promotes promiscuity\n",
    "    'PRO',  # government intervention could serve a useful purpose\n",
    "    'CON',  # democracy will result in the people's distrust and disrespect of governments\n",
    "    'PRO',  # the expression of dissent or subversive views should be tolerated\n",
    "    'CON',  # reliance on divine authority lends itself to authoritarianism and dogmatism\n",
    "    'CON',  # the consequences of Israels failure to maintain the blockade would be an Iranian port in Gaza, only a few dozen kilometers from Tel Aviv and Jerusalem\n",
    "    'CON',  # A homogeneous community grounded on consensus may be unable to criticize the injustice and exclusionary practices that undermine it\n",
    "    'CON',  # Certain restrictions on abortion could be used to form a slippery slope against all abortions\n",
    "    'CON',  # allowing property rights in ideas and information creates artificial scarcity\n",
    "    'CON',  # Multiculturalism would lead to acceptance of barbaric practices\n",
    "    'CON',  # violent video games are significantly associated with: increased aggressive behavior, thoughts, and affect; increased physiological arousal; and decreased pro-social (helping) behavior\n",
    "    'PRO',  # The possibility of getting shot by an armed victim is a substantial deterrent to crime\n",
    "    'CON',  # abortion causes mental health problems\n",
    "    'CON',  # prohibiting people from using, reproducing, and trading copyrighted material is an infringement of freedom of speech\n",
    "    'CON'   # Freedom of speech does not allow a person to contempt the courts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb27ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted stances adding topics\n",
    "pred_stances2 = [\n",
    "    'PRO',  # intellectual property rights\n",
    "    'CON',  # atheism\n",
    "    'CON',  # build hydroelectric dams\n",
    "    'CON',  # the one-child policy of the republic of China\n",
    "    'CON',  # unleash the free market\n",
    "    'CON',  # Israel's 2008-2009 military operations against Gaza\n",
    "    'PRO',  # gambling\n",
    "    'CON',  # build hydroelectric dams\n",
    "    'CON',  # build hydroelectric dams\n",
    "    'PRO',  # the one-child policy of the republic of China\n",
    "    'CON',  # build hydroelectric dams\n",
    "    'CON',  # Israel's 2008-2009 military operations against Gaza\n",
    "    'PRO',  # the monarchy\n",
    "    'CON',  # unleash the free market\n",
    "    'CON',  # advertising\n",
    "    'PRO',  # the sale of violent video games to minors\n",
    "    'CON',  # advertising\n",
    "    'CON',  # atheism\n",
    "    'PRO',  # intellectual property rights\n",
    "    'CON',  # atheism\n",
    "    'CON',  # subsidize poor communities\n",
    "    'CON',  # freedom of speech\n",
    "    'CON',  # only teach abstinence for sex education in schools\n",
    "    'PRO',  # freedom of speech\n",
    "    'CON',  # unleash the free market\n",
    "    'CON',  # atheism\n",
    "    'CON',  # atheism\n",
    "    'PRO',  # have children\n",
    "    'PRO',  # gambling\n",
    "    'CON',  # atheism\n",
    "    'CON',  # only teach abstinence for sex education in schools\n",
    "    'CON',  # subsidize poor communities\n",
    "    'CON',  # the blockade of Gaza\n",
    "    'PRO',  # have children\n",
    "    'CON',  # advertising\n",
    "    'CON',  # only teach abstinence for sex education in schools\n",
    "    'PRO',  # unleash the free market\n",
    "    'CON',  # democratization\n",
    "    'PRO',  # freedom of speech\n",
    "    'CON',  # atheism\n",
    "    'CON',  # the blockade of Gaza\n",
    "    'CON',  # multiculturalism\n",
    "    'CON',  # partial birth abortions\n",
    "    'PRO',  # intellectual property rights\n",
    "    'CON',  # multiculturalism\n",
    "    'PRO',  # the sale of violent video games to minors\n",
    "    'PRO',  # the right to bear arms\n",
    "    'CON',  # partial birth abortions\n",
    "    'PRO',  # intellectual property rights\n",
    "    'CON'   # freedom of speech\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0650856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test['stance'][:50], pred_stances, labels=['PRO', 'CON'])\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['PRO', 'CON']).plot(ax=ax)\n",
    "plt.savefig(plots_path+'chatGPT_cm.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ca340",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test['stance'][:50], pred_stances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test['stance'][:50], pred_stances2, labels=['PRO', 'CON'])\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['PRO', 'CON']).plot(ax=ax)\n",
    "plt.savefig(plots_path+'chatGPT_cm2.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314ab157",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test['stance'][:50], pred_stances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8d34c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
